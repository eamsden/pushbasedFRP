\section{Signal Functions}
\label{section:Implementation-Signal_Functions}

The design of signal functions specifies a family of types for the inputs and
outputs of signal functions. Signal functions are not functions in the purest
sense, however. They are not mappings from a single instance of their input
type to a single instance of their output type. They must be implemented with
respect to the temporal semantics of their inputs and outputs.

We therefore start by creating a set of concrete datatypes for the inputs and
outputs of signal functions. These datatypes will be parameterized by the input
and output types of the signal function, and will not be exposed to the user of
the library. Rather, they will specify how data is represented during the
temporal evaluation of signal functions.

We then describe how signal functions are implemented using these concrete
types, along with higher-order functions and continuations.

\subsection{Concrete Representations of Signal Vectors}
\label{subsection:Concrete_Representations_of_Signal_Vectors}

In Chapter~\ref{chapter:System_Design_and_Interface} we presented signal vectors
as a set of types. In order to be completely principled, we should isolate these
types into their own {\em kind} (a sort of type of types); however, the Haskell
extension for this was far from stable at the time this system was created.

The types are therefore expressed in the system exactly as they were described
in Chapter~\ref{chapter:System_Design_and_Interface}. (To refresh, see
Figure~\ref{figure:signal_vector_types}.) The striking observation about these
types is that they have {\em no data constructors}. There are no values which
have these types.

Instead, we will create concrete representations which are parameterized over
these types. These concrete representations will be expressed as GADTs, allowing
each data constructor of the representation to fill in a specific signal vector
type for the parameter of the representation.

The first thing to represent is {\em samples}, which are sets of values for
the signal components of a signal vector. Therefore, we create a representation
which carries a value for every {\tt SVSignal} leaf of a signal vector. In order
to do this, we restrict each of our constructors to a single signal vector type.
So there are three leaf constructors: {\tt SVSample}, which carries a value; and
{\tt SVSampleEvent} and {\tt SVSampleEmpty}, which do not. This ensures that the
only way to represent a sample leaf is with the {\tt SVSample} constructor,
which carries a value of the appropriate type. The datatype is shown in
Figure~\ref{figure:signal_sample_datatype}.

\begin{figure}
\begin{code}
data SVSample sv where
  -- Store a value at an SVSignal leaf
  SVSample      ::    a
                   -> SVSample (SVSignal a)
  -- Empty constructor for event leaves
  SVSampleEvent ::    SVSample (SVEvent a)
  -- Empty constructor for empty leaves
  SVSampleEmpty ::    SVSample SVEmpty
  -- Construct a sample from two samples, typed
  --  with the SVAppend of their signal vectors
  SVSampleBoth  ::    SVSample svLeft
                   -> SVSample svRight
                   -> SVSample (SVAppend svLeft svRight)
\end{code}
\hrule
\caption{Datatype for signal samples.}
\label{figure:signal_sample_datatype}
\end{figure}

What about the event components? We want to represent event occurrences,
each of which will correspond to at most one event in the vector. So a different
representation is called for. In this case, there will be only three
constructors. One constructor will represent an event leaf, and the other will
represent a single value on the left or right side of the node ({\tt SVAppend}),
ignoring all of the type structure on the other side. This representation
describes a path from the root of the signal vector, terminating at an event
leaf with a value.

By pattern matching on the path constructors, we can determine which subvector
of a signal vector an event occurrence belongs to, repeatedly refining it until
we determine which event in the vector the occurrence corresponds to. The
datatype for occurrences is shown in Figure~\ref{figure:event_occurrence_datatype}.

\begin{figure}
\begin{code}
data SVOccurrence sv where
  -- Leaf, carrying a value for the occurrence
  SVOccurrence ::    a
                  -> SVOccurrence (SVEvent a)
  -- Lift an occurrence to be on the left side of a signal vector
  SVOccLeft    ::    SVOccurrence svLeft
                  -> SVOccurrence (SVAppend svLeft svRight)
  -- Lift an occurrence to be on the right side of a signal vector
  SVOccRight   ::    SVOccurrence svRight 
                  -> SVOccurrence (SVAppend svLeft svRight)
\end{code}
\hrule
\caption{Datatype for event occurrences.}
\label{figure:event_occurrence_datatype}
\end{figure}

We add one more representation for signals, in order to avoid uneccessary
representations of the values of all signals when not all signals have changed
their values. This representation allows us to represent the values of zero or
more of the signals in a signal vector. To accomplish this, we replace the
individual constructors for the {\tt SVEmpty} and {\tt SVEvent} leaves with %there is a better word, something about "useless but not really", for this
a single, unconstrained constructor. This constructor can represent an arbitrary
signal vector. We can use the constructor for signal vector nodes and the 
constructor for sample leaves to represent the updated values, while filling
in the unchanged portions of the signal vector with this general constructor.
This datatype is shown in Figure~\ref{figure:signal_update_datatype}.

\begin{figure}
\begin{code}
data SVDelta sv where
  -- A replacement value for a sample of a single signal
  SVDeltaSignal  ::    a
                    -> SVDelta (SVSignal a)
  -- No replacement value for a sample of an arbitrary
  --  signal vector
  SVDeltaNothing ::    SVDelta sv
  -- Combine replacements for component signal vectors into 
  --   replacements for the SVAppend of the vectors.
  SVDeltaBoth    ::    SVDelta svLeft
                    -> SVDelta svRight
                    -> SVDelta (SVAppend svLeft svRight)
\end{code}
\hrule
\caption{Datatype for signal updates.}
\label{figure:signal_update_datatype}
\end{figure}

\subsection{Signal Function Implementation Structure}
\label{subsection:Implementation-Signal_Functions-Signal_Function_Implementation_Structure}

We now have concrete datatypes for an implementation to operate on. Our next
task is to represent transformers of temporal data, which themselves may change
with time. The common approach to this task is sampling, in which a program
repeatedly checks for updated information, evaluates it, updates some state,
and produces an output. This is the essence of pull-based evaluation.

Another approach is notification, in which the program exposes an interface
which the source of updated information may invoke. This is a repeated entry
point to the program, which causes the program to perform the same tasks
listed above, namely, evaluate the updated information, update state, and
produce output. The strategy of notification as opposed to repeated checking is
the essence of push-based evaluation.

Signal functions are declarative objects, and not running processes. They have
no way to invoke sampling themselves. They can, however, expose separate
interfaces for when sampling is invoked, and when they are notified of an event
occurrence. This creates two control paths through a signal function. One of
these control paths is intended to be invoked regularly and frequently with
updates to the time and sample values, and the other is intended to be invoked
only when an event occurs. The benefit of separating these control paths is that
events are no longer defined in terms of sampling intervals, and need not even
be considered in sampling, except when they are generated by a condition on a
sample. On the other hand, events can be responded to even if the time has not
yet come for another sample, and multiple events can be responded to in a single
sampling interval.

We represent signal functions as a GADT with three type parameters and two 
constructors. The first type parameter represents the initialization state,
and is specialized to {\tt Initialized} or {\tt NonInitialized} depending on the
constructor. The other two type parameters are the input and output signal
vectors, respectively. The signal functions that a user will compose are\
non-initialized signal functions. They must be provided with an initial set of
input signals (corresponding to time zero). When provided with this input, they
produce their time-zero output, and an initialized signal function. The datatype
is shown in Figure~\ref{figure:signal_function_datatype}.

\begin{figure}
\begin{code}
-- Type tag for signal functions which don't require
--  an initial input
data Initialized

-- Type tag for signal functions which require
--  an initial input
data NonInitialized

-- Type of signal functions
data SF init svIn svOut where
  -- Non-initialized signal functions consist of a function
  --  from an input sample to a pair of an output sample
  --  and an initialized continuation of the signal function
  SF     ::    (SVSample svIn 
                  -> (SVSample svOut,
                      SF Initialized svIn svOut)) 
            -> SF NonInitialized svIn svOut
  
  -- Initialized signal functions consist of two functions.
  -- The first function's inputs are the time delta, and updates
  --   to the input signals. Its outputs are updates to the output
  --   signals, a set of output events, and a continuation of the
  --   signal function.
  SFInit ::    (Double 
                  -> SVDelta svIn
                  -> (SVDelta svOut,
                      [SVOccurrence svOut],
                      SF Initialized svIn svOut)) 

  -- The second function's input is an event occurrence for an
  --   event in its input signal vector. Its outputs are a set 
  --   of output occurrences for events in its output signal
  --   vector, and a continuation of the signal function.
            -> (SVOccurrence svIn
                  -> ([SVOccurrence svOut],
                      SF Initialized svIn svOut))
            -> SF Initialized svIn svOut
\end{code}
\hrule
\caption{Datatype and empty types for signal functions.}
\label{figure:signal_function_datatype}
\end{figure}

Initialized signal functions carry two continuations. The first continuation
takes a time differential and a set of signal updates, and returns a set of
signal updates, a collection of event occurrences, and a new initialized signal
function of the same type. This is the continuation called when sampling.

The second continuation takes an event occurrence, and returns a collection of
event occurrences and a new signal function of the same type. This continuation
is only called when there is an event occurrence to be input to the signal
function.

Note that each of these continuations uses one or more of the concrete
representations of signal vectors, and applies the type constructor for the
representation to the input or output signal vector for the signal function.

\subsection{Implementation of Signal Function Combinators}
\label{subsection:Implementation-Signal_Functions-Implementation_of_Signal_Function_Combinators}

Having specified a datatype for signal functions, we must now provide
combinators which produce signal functions of this type. Each combinator's
implementation must specify how it is initialized, how it samples its input, and
how it responds to event occurrences.

We will not detail every combinator here, but we will discuss each of the
implementation challenges encountered.

As an example of the implementation of combinators, we show the implementation
of the {\tt identity} signal function in Figure~\ref{figure:identity_implementation}.
This signal function simply passes all of its inputs along as outputs. The
initialization function simply passes along the received sample and outputs the
initialized version of the signal function. The initialized version of the input
is similar, but is self-referential. It outputs itself as its replacement. This
is standard for simple and routing combinators which are not reactive, and
simply move samples and event occurrences around.

\begin{figure}
\begin{code}
identity :: sv :~> sv
identity =
  SF (\initSample -> (initSample, identityInit))

identityInit :: SF Initialized sv sv
identityInit =
  SFInit (\dt sigDelta -> (sigDelta, [], identityInit))
         (\evtOcc -> ([evtOcc], identityInit))
\end{code}
\hrule
\caption{Implementation of the {\tt identity} combinator.}
\label{figure:identity_implementation}
\end{figure}

In order for our primitive signal functions to be useful, we need a means of
composing them. Serial composition creates one signal function from two, by
using the output of one as the input of the other. The serial composition
combinator is styled {\tt (>>>)}. The implementation of this operator is one
place where the advantage of responding to events independently from signal
samples becomes clear. 

This is the only primitive combinator which takes two signal functions, and
thus, it is the only way to combine signal functions. Parallel, branching, and
joining composition can be achieved by modifying signal functions with the
{\tt first} and {\tt second} combinators and composing them with the
routing and joining combinators.

Combinators which take one or more signal functions as input must recursively
apply themselves, as is shown in the implementation of serial composition
(Figure~\ref{figure:serial_composition_implementation}). They must also
handle initialization, retaining the initialized signal functions and passing
them to the initialized version of the combinator.

\begin{figure}
\begin{code}
(>>>) ::    (svIn :~> svBetween) 
         -> (svBetween :~> svOut)
         -> (svIn :~> svOut)
(SF sigSampleF1) >>> (SF sigSampleF2) =
  SF (\sigSample -> let (sigSample', sfInit1) = sigSampleF1 sigSample
                        (sigSample'', sfInit2) = sigSampleF2 sigSample'
                    in (sigSample'', composeInit sfInit1 sfInit2))

composeInit ::     SF Initialized svIn svBetween
                -> SF Initialized svBetween svOut
                -> SF Initialized svIn svOut
composeInit (SFInit dtCont1 inputCont1) sf2@(SFInit dtCont2 inputCont2) =
  SFInit
    (\dt sigDelta -> 
       let (sf1MemOutput, sf1EvtOutputs, sf1New) = dtCont1 dt sigDelta
           (sf2MemOutput, sf2EvtOutputs, sf2New) = dtCont2 dt sf1MemOutput
           (sf2EvtEvtOutputs, sf2Newest) = applySF sf2New sf1EvtOutputs
       in (sf2MemOutput,
           sf2EvtOutputs ++ sf2EvtEvtOutputs,
           composeInit sf1New sf2Newest)
    )
    (\evtOcc -> 
      let (sf1Outputs, sf1New) = inputCont1 evtOcc
          (sf2FoldOutputs, sf2New) = applySF sf2 sf1Outputs
      in (sf2FoldOutputs, composeInit sf1New sf2New)   
    )

-- The programmer should not rely on any 
applySF ::    SF Initialized svIn svOut
           -> [SVOccurrence svIn]
           -> ([SVOccurrence svOut],
               SF Initialized svIn svOut)
applySF sf indices =
  foldr (\evtOcc (changes, SFInit _ changeCont) ->
           let (newChanges, sfNew) = changeCont evtOcc
               in (newChanges ++ changes, sfNew))
        ([], sf)
        indices
\end{code}
\hrule
\caption{Implementation of serial composition.}
\label{figure:serial_composition_implementation}
\end{figure}

The {\tt switch} combinator is the means of introducing reactivity into a signal
function. This combinator allows a signal function to replace itself by
producing an event occurrence. The combinator wraps a signal function, and 
observes an event on the right side of the output signal vector. At the first
occurrence of the event, the signal function carried by the occurrence replaces
the signal function. 

The {\tt switch} combinator stores the input sample provided during initialization,
and updates it with the input signal updates. When the wrapped signal function
produces an occurrence carrying a new signal function, that signal function is
initialized with the stored input sample. It is then ``wrapped'' by another
function which closes over its output sample, and outputs the sample as a signal
update as the next time step. After this, it acts as the new signal function.
This wrapping has some performance implications, which are discussed in Chapter~\ref{chapter:Evaluation_and_Comparisons}.

This combinator checks the outputs of the wrapped
signal function for an event occurrence from which an uninitialized signal
function is extracted. The switch combinator stores the full sample
for its input vector (which is identical to the input vector of the supplied
signal function) to initialize the new signal function. This also demands that
it add a wrapper to the new signal function which waits for the next sampling
interval and actuates the sample output at initialization as an output set
of changes to the signal. This has some performance implications, which are
discussed in Chapter~\ref{chapter:Evaluation_and_Comparisons}.

Most of the routing combinators are simple to implement. The only task is to add
remove, or replace routing constructors on signal updates and event occurrences.
Since these signal functions are stateless and primitive, they can simply
return themselves as their replacements. The {\tt swap} combinator is shown as
an example in Figure~\ref{figure:swap_implementation}

\begin{figure}
\begin{code}
-- T.swap is imported from Data.Tuple
-- chooseOccurrence, splitSample, splitDelta,
--  combineSamples, combineDeltas, occRight, and
--  occLeft are convenience functions for manipulating
--  signal sample
swap :: (sv1 :^: sv2) :~> (sv2 :^: sv1)
swap =
  SF (\sigSample ->  
       (uncurry combineSamples $ T.swap $ splitSample sigSample, 
        swapInit)

swapInit :: SF Initialized (SVAppend sv1 sv2) (SVAppend sv2 sv1)
swapInit =
  SFInit (\_ sigDelta ->
           (uncurry combineDeltas $ T.swap $ splitDelta sigDelta,
            swapInit) 
         (\evtOcc ->
            (case chooseOccurrence evtOcc of
               Left lOcc  -> [occRight lOcc]
               Right rOcc -> [occLeft rOcc], swapInit))

\end{code}
\hrule
\caption{Implementation of the {\tt swap} routing combinator.}
\label{figure:swap_implementation}
\end{figure}

The {\tt first} and {\tt second} combinators are similar to serial composition,
but they transform only one signal function. For signal changes, they must split
the set of input changes into those which will be passed to the signal function
and those which will be simply passed along to the output, and then recombine
them on the other side. For event occurrences, the occurrence must be
pattern-matched to determine whether to call the event continuation from the
provided signal function or passed through, and output event occurrences must
have the suitable routing constructor re-applied. In any case, when a
continuation has been applied, the combinator must be recursively applied to the
new signal function.

The looping feedback combinator is particularly tricky. As it is currently
implemented, the initial sample for the right side of the input signal vector to
the supplied function is the right side of the output sample. This is acceptable,
given Haskell's non-strict evaluation strategy, but it is necessary that the
right side of the signal function's output not be immediately dependent on its
input. The feedback combinator makes use of Haskell's lazy evaluation to
feed events back into the combinator, and stores signal updates until the next
sample. Signal samples are thus automatically decoupled after initialization.
The implementation makes use of the recursive nature of the {\tt let} construct
in Haskell, and the non-strict evaluation of Haskell, to implement feedback.


The {\tt filter} combinators are simple to implement. Their sampling
continuation is superfluous, and the event continuation merely applies the
supplied function, and constructs an output list based on the result.

The {\tt accumulate} combinators are implemented in terms of the {\tt filter}
and {\tt switch} combinators, as shown in
Figure~\ref{figure:accumulate_implementation}.

\begin{figure}
\begin{code}
-- | Accumulate over event occurrences
accumulate :: (a -> b -> (Maybe c, a)) -> a -> SVEvent b :~> SVEvent c
accumulate f a = acc a
  where acc a = switch (pureEventTransformer (f a) >>>
                        copy >>>
                        first (pureEventTransformer fst >>> filter id) >>>
                        second (pureEventTransformer (acc . snd)))

-- | Accumulate over event occurrences, with lists of event outputs
accumulateList :: (a -> b -> ([c], a)) -> a -> SVEvent b :~> SVEvent c
accumulateList f a = acc a
  where acc a = switch (pureEventTransformer (f a) >>>
                        copy >>>
                        first (pureEventTransformer fst >>> filterList id) >>>
                        second (pureEventTransformer (acc . snd)))
\end{code}
\hrule
\caption{Implementation of event accumulators.}
\label{figure:accumulate_implementation}
\end{figure}

The {\tt union} combinator's implementation passes along every event occurrence 
it receives on either input, stripping off the left and right combinator. This is 
acceptable since we do not insist on a total ordering of events, or an event time
resolution greater than the sampling rate. The {\tt combineSignals} combinator 
maintains the values of both signals, and applies the combination function whenever
one is updated, producing an update to the output signal's value.
The {\tt capture} combinator similarly maintains the input signal value, and adds it
to each event occurrence.

Time dependence is introduced by the {\tt time}, {\tt delay}, and {\tt integrate}
combinators. The time combinator simply sums the time updates and provides the
sum as a signal output. The {\tt delay} combinator keeps a table of events
which have come in, along with their schedule occurrence time, and produces
them as output when time advances far enough. The integrate combinator performs
rectangle-rule integration on signal samples with respect to time.

The implementation strategy leaves room for optimizations. In particular, an
additional constructor for time-independent signal functions would allow
portions of a signal function to forgo evaluation during time steps unless they
had signal updates. Optimizations in the style of Yampa, where an AST for the
current signal function is maintained alongside the continations and checked for
opportunities to eliminate redundant components of the signal function,
might further improve performance. In particular, collapsing nested or
serially-composed switches which have occurred since the last time step would
remove at least some of the observed dependence of performance on sampling rate.
Nevertheless, this implementation performs quite well as it currently exists, as
we demonstrate in Chapter~\ref{chapter:Evaluation_and_Comparisons}.
