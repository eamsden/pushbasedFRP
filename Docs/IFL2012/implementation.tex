\section{Implementation}
\label{section:Implementation}

We now turn our attention to the implementation of the signal function
system. We will discuss representations of inputs, outputs, and signal functions,
as well as the implementations of specific signal function combinators.

\subsection{Signal Functions}
\label{subsection:Implementation-Signal_Functions}

The design of signal functions specifies a family of types for the inputs and
outputs of signal functions. Signal functions are not functions in the purest
sense, however. They are not mappings from a single instance of their input
type to a single instance of their output type. They must be implemented with
respect to the temporal semantics of their inputs and outputs.

We therefore start by creating a set of concrete datatypes for the inputs and
outputs of signal functions. These datatypes will be parameterized by the input
and output types of the signal function, and will not be exposed to the user of
the library. Rather, they will specify how data is represented during the
temporal evaluation of signal functions. We then implement signal functions
as records of functions from these concrete types to these concrete types paired
with new signal functions. The evaluation system for signal functions then
maintains this record for the signal function it is evaluating, calls the
correct function for the current input, actuates the outputs (using supplied
functions from the outputs to monadic actions) and replaces the record with the
newly supplied signal function record.

In Section~\ref{section:System_Design_and_Interface} we presented signal vectors
as a set of types. In order to be completely principled, we should isolate these
types into their own {\em kind} (a sort of type of types); however, the Haskell
extension for this was far from stable at the time this system was created.

Using the Glasgow Haskell Compiler's extension for Generalized Algebraic
Datatypes~\cite{Cheney2003,Xi2003,PeytonJones2006}, we specify three concrete
datatypes which are parameterized over signal vectors, and represent
information about one temporal point in a signal function's evaluation.

The first type carries the instantaneous values of all signals in a signal vector.
There is precisely one constructor for each type constructor of a signal vector ({\tt SVEmpty},
{\tt SVSignal}, {\tt SVEvent}, and {\tt SVAppend}). The constructor for {\tt SVSignal}
carries a value typed with the type parameter of the {\tt SVSignal} constructor,
the rest do not. Thus, in this representation, for any signal vector, there is
a node in the representation for each node in the signal vector, and precisely
the signal nodes have values.

The next representation contains a constructor for {\tt SVEvent} nodes, carrying
a value typed by the type parameter of {\tt SVEvent}, and two constructors, each
of which carries a representation for one child of a {\tt SVAppend} node (the
left or right), and is parametric in the other. Thus, an instance of this
representation is a path from the root of a signal vector to an event node,
carrying exactly one value for the event.

The last representation is used for efficient implementation, and has three
constructors. One constructor represents a {\tt SVSignal} node and has a value
typed by its type parameter. The second carries representations of both
children of a {\tt SVAppend} node. The third is parametric in its signal vector,
and thus represents the absence of information for an arbitrary signal vector.
This representation contains values for all, some, or none of the {\tt SVSignal}
nodes of a signal vector.

Signal functions are implemented by combining two strategies for temporal
updates. The first such strategy is sampling. A signal function has a 
continuation which may be invoked at regular intervals, using the partial
representation of signals described above as input and producing such a
representation as output. This amounts to repeated sampling of the output
signals of a signal function.

The other approach is notification. Signal functions have a second continuation
which is only invoked when there is an event occurence on their input. The input
to this continuation is, of course, the representation of event occurrences. If
events were signals, they would be sampled as above, and the sampling interval
would not match the event occurrence interval. It would thus be necessary to
represent these non-occurrences. By implementing event handling separately from
signal updates, we eliminate the need for a representation of event
non-occurences and the need for invoking event-handling code at every time step.

We represent signal functions as a GADT with three type parameters and two 
constructors. The first type parameter represents the initialization state,
and is specialized to {\tt Initialized} or {\tt NonInitialized} depending on the
constructor. It would of course be possible to represent these as two distinct
datatypes, but this representation communicates the intuition that these are
two states of the same object, rather than separate objects. The other two type
parameters are the input and output signal vectors, respectively. The signal
functions that a user will compose are non-initialized signal functions.
They must be provided with an initial set of input signal values, which are considered
the sample for time zero, and represented by the full representation of signals
described above. When provided with this input, they produce their time-zero
output and an initialized signal function.

Initialized signal functions carry the two continuations described above.
The first continuation takes a time differential and a set of signal updates
(the partial representation of signals) and returns a set of signal updates, a
collection of event occurrences, and a new initialized signal function of the
same type. This is the continuation called when sampling.

The second continuation takes an event occurrence, and returns a collection of
event occurrences and a new signal function of the same type. This continuation
is only called when there is an event occurrence to be input to the signal
function.

This is the type and framework for our signal function implementation.
Combinators are implemented as functions which return these types with specific
implementations of the continuations. Space precludes a full discussion of the
implemenation of each combinator, but some of the examples will be discussed.

The simplest example of the implementation of is the {\tt identity} combinator,
shown in Figure~\ref{figure:identity_implementation}. This signal function
simply passes all of its inputs along as outputs. The initialization function
simply passes along the received sample and outputs the initialized version of
the signal function. The initialized version of the input is similar, but is
self-referential. It outputs itself as its replacement. This is standard for
simple and routing combinators which are not reactive, and simply re-arrange,
discard, or combine signals and events.

In order for our primitive signal functions to be useful, we need a means of
composing them. Serial composition creates one signal function from two, by
using the output of one as the input of the other. The serial composition
combinator is styled {\tt (>>>)}. The implementation of this operator is one
place where the advantage of responding to events independently from signal
samples becomes clear. 

This is the only primitive combinator which takes two signal functions, and
thus, it is the only way to combine signal functions. Parallel, branching, and
joining composition can be achieved by modifying signal functions with the
{\tt first} and {\tt second} combinators and composing them with the
routing and joining combinators.

Combinators which take one or more signal functions as input must recursively
apply themselves, as is shown in the implementation of serial composition
(Figure~\ref{figure:serial_composition_implementation}). They must also
handle initialization, retaining the initialized signal functions and passing
them to the initialized version of the combinator.

The switch combinator is the means of introducing reactivity into a signal
function. This combinator allows a signal function to replace itself by
producing an event occurrence. The combinator wraps a signal function, and 
observes an event on the right side of the output signal vector. At the first
occurrence of the event, the signal function carried by the occurrence replaces
the signal function. 

The switch combinator stores the input sample provided during initialization,
and updates it with the input signal updates. When the wrapped signal function
produces an occurrence carrying a new signal function, that signal function is
initialized with the stored input sample. It is then "wrapped" by another
function which closes over its output sample, and outputs the sample as a signal
update as the next time step. After this, it acts as the new signal function.
This wrapping has some performance implications, which are discussed in Section~\ref{section:Discussion}.

This combinator checks the outputs of the wrapped
signal function for an event occurrence from which an uninitialized signal
function is extracted. The switch combinator stores the full sample
for its input vector (which is identical to the input vector of the supplied
signal function) to initialize the new signal function. This also demands that
it add a wrapper to the new signal function which waits for the next sampling
interval and actuates the sample output at initialization as an output set
of changes to the signal. This has some performance implications, which are
discussed in Chapter~\ref{chapter:Evaluation_and_Comparisons}.

Most of the routing combinators are simple to implement. The only task is to add
remove, or replace routing constructors on signal updates and event occurrences.
Since these signal functions are stateless and primitive, they can simply
return themselves as their replacements. The {\tt swap} combinator is shown as
an example in Figure~\ref{figure:swap_implementation}

The looping feedback combinator is particularly tricky. As it is currently
implemented, the initial sample for the right side of the input signal vector to
the supplied function is the right side of the output sample. This is acceptable,
given Haskell's non-strict evaluation strategy, but it is necessary that the
right side of the signal function's output not be immediately dependent on its
input. The feedback combinator makes use of Haskell's lazy evaluation to
feed events back into the combinator, and stores signal updates until the next
sample. Signal samples are thus automatically decoupled after initialization.
The implementation makes use of the recursive nature of the {\tt let} construct
in Haskell, and the non-strict evaluation of Haskell, to implement feedback.

Time dependence is introduced by the {\tt time}, {\tt delay}, and {\tt integrate}
combinators. The time combinator simply sums the time updates and provides the
sum as a signal output. The {\tt delay} combinator keeps a table of events
which have come in, along with their schedule occurrence time, and produces
them as output when time advances far enough. The integrate combinator performs
rectangle-rule integration on signal samples with respect to time.

The implementation strategy leaves room for optimizations. In particular, an
additional constructor for time-independent signal functions would allow
portions of a signal function to forgo evaluation during time steps unless they
had signal updates. Optimizations in the style of Yampa, observed by keeping
an updated AST for the signal function and pattern-matching on it when switching,
might further improve performance. In particular, collapsing nested or
serially-composed versions of the {\tt switchWait} step when switching would
remove at least some of the observed dependence of performance on sampling rate.
Nevertheless, this implementation performs quite well as it currently exists, as
we demonstrate in Chapter~\ref{chapter:Evaluation_and_Comparisons}.

\subsection{Evaluation Interface}
\label{subsection:Implementation-Evaluation_Interface}
The evaluation interface provides the means of evaluating a signal function
with inputs and producing effects in response to the signal function's outputs.
We would like to produce a set of constructs that interacts well with Haskell's
system for external IO.

The evaluation interface translates between signal functions and the standard
Haskell construct for sequencing effects and external inputs, namely,
{\em monads}~\cite{PeytonJones1993}. The inspiration for monads is drawn from
the rather esoteric domain of category theory, but the concept as applied to
programming languages is actually rather simple.

By formulating
the evaluation interface as a monad transformer, we need only define the
operations relevant to the evaluation of signal functions, and we can depend
on the constructs of the IO monad to interact with whatever inputs and outputs
are necessary. In some cases, we may not wish to use the IO monad at all (e.g
for testing or simulation). In this case, we can parameterize over another
monad, such as the Identity monad (which has no special operations and whose
context is just the value), or the State monad (which maintains an implicit 
state accessible by {\tt get} and {\tt put} operations).

The evaluation interface is exported as shown in
Section~\ref{section:System_Design_and_Interface-Evaluator}.

The {\tt SFEvalState} type constructor parameterizes over input types for signal
functions, and underlying monads for a monad transformer, but is not itself
a monad transformer. It describes the state of signal function evaluation.
It consists of a record with four members: the current signal function,
the set of handlers for outputs, the current input signal delta, and the last
sample time.

The {\tt SFEvalT} monad transformer does not make the {\tt get} and {\tt put}
actions available, but uses them in its implementation of the {\tt push},
{\tt update}, and {\tt sample} actions.

The {\tt push} action pushes an event onto the input of the signal function,
resulting in immediate evaluation of the relevant components signal function
and possible actuation of handlers specified for output events. It is
implemented by fetching the {\tt SFEvalState}, applying the event continuation
of the signal function contained by the {\tt SFEvalState} to the pushed event,
thus obtaining a new signal function and a list of events, applying the handlers
contained in the {\tt SFEvalState} to the output events, replacing the signal
function in the {\tt SFEvalState}, and replacing the {\tt SFEvalState}.

The {\tt update} action updates the current input signal delta, which will be
sampled at the next {\tt step} action. It has no immediately observable effect.
It simply updates the value of one signal in the input signal vector, a delta
of which is stored in the {\tt SFEvalState} record.

The {\tt step} action takes a time delta, and calls the signal continuation of
the stored signal function. It actuates the outputs using the stored handlers,
replaces the stored delta with an empty delta, and stores the resulting new
signal function in the state.
